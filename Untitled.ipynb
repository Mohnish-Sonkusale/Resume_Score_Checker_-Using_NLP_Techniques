{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7300e975-a6fa-4ee5-91e5-29c889687c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8999b3-13f8-4aa2-befb-144fb13b4f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Skills</th>\n",
       "      <th>exp</th>\n",
       "      <th>des</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backend Developer</td>\n",
       "      <td>NumPy,Pandas,ORM,Jinja2,PostGRESQL,GIT,SVN,LIN...</td>\n",
       "      <td>2</td>\n",
       "      <td>Backend Developer - Python/Django    We are lo...</td>\n",
       "      <td>back developer  patrondjango    look patrondja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/ ML Engineer</td>\n",
       "      <td>R,Python,k-NN, Naive Bayes,SVM,Decision Forest...</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist/ ML Engineer  Game Change Solut...</td>\n",
       "      <td>data scientist engineer  game change solution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>HTML,CSS,PHP,JavaScript,\\r\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>Web Developer  We are looking for an outstandi...</td>\n",
       "      <td>web developer  look outstanding web developer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>PHP,HTML,Angular,Code Igniter</td>\n",
       "      <td>3</td>\n",
       "      <td>Senior Software Developer  Senior Software Eng...</td>\n",
       "      <td>senior software developer  senior software eng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Job   \\\n",
       "0            Backend Developer   \n",
       "1  Data Scientist/ ML Engineer   \n",
       "2                Web Developer   \n",
       "3    Senior Software Engineer    \n",
       "\n",
       "                                             Skills   exp  \\\n",
       "0  NumPy,Pandas,ORM,Jinja2,PostGRESQL,GIT,SVN,LIN...    2   \n",
       "1  R,Python,k-NN, Naive Bayes,SVM,Decision Forest...    1   \n",
       "2                       HTML,CSS,PHP,JavaScript,\\r\\n    1   \n",
       "3                      PHP,HTML,Angular,Code Igniter    3   \n",
       "\n",
       "                                                 des  \\\n",
       "0  Backend Developer - Python/Django    We are lo...   \n",
       "1  Data Scientist/ ML Engineer  Game Change Solut...   \n",
       "2  Web Developer  We are looking for an outstandi...   \n",
       "3  Senior Software Developer  Senior Software Eng...   \n",
       "\n",
       "                                            cleaned   \n",
       "0  back developer  patrondjango    look patrondja...  \n",
       "1  data scientist engineer  game change solution ...  \n",
       "2  web developer  look outstanding web developer ...  \n",
       "3  senior software developer  senior software eng...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleanedDataJob.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe0a4e9f-e6bd-4072-b810-0145177c25e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job                               Data Scientist/ ML Engineer\n",
       "Skills      R,Python,k-NN, Naive Bayes,SVM,Decision Forest...\n",
       "exp                                                         1\n",
       "des         Data Scientist/ ML Engineer  Game Change Solut...\n",
       "cleaned     data scientist engineer  game change solution ...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3618dd48-f093-433c-87a9-4a757a4ab3de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m job_des_cln = df.at[\u001b[43mjob_name\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mcleaned \u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'job_name' is not defined"
     ]
    }
   ],
   "source": [
    "job_des_cln = df.at[job_name, 'cleaned ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bcedcde-a37b-454c-aea2-56e3d158e007",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m job_row = df[df[\u001b[33m'\u001b[39m\u001b[33mJob \u001b[39m\u001b[33m'\u001b[39m] == \u001b[43mjob_name\u001b[49m].iloc[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# Get the first match (in case of multiple matches)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Get the relevant columns\u001b[39;00m\n\u001b[32m      4\u001b[39m job_des_cln = job_row[\u001b[33m'\u001b[39m\u001b[33mcleaned\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# Preprocessed job description\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'job_name' is not defined"
     ]
    }
   ],
   "source": [
    "job_row = df[df['Job '] == job_name].iloc[0]  # Get the first match (in case of multiple matches)\n",
    "    \n",
    "# Get the relevant columns\n",
    "job_des_cln = job_row['cleaned']  # Preprocessed job description\n",
    "print(\"Preprocessed Job Description:\", job_des_cln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665a29f7-3172-4071-ae5e-87b07b203747",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m option = \u001b[33m\"\u001b[39m\u001b[33mData scientist/machine learning\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m index = \u001b[43midx\u001b[49m[option]\n",
      "\u001b[31mNameError\u001b[39m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "option = \"Data scientist/machine learning\"\n",
    "index = idx[option]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e5cc238-d99c-476a-a428-72eddc177360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc93af7b-c67f-42ff-baa6-b4c388b667e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 \n",
    "# import textract\n",
    "def read_resume():\n",
    "    # if ext =='application/pdf':\n",
    "    #     with open(\"temp.pdf\", 'wb') as f:\n",
    "    #         f.write(byted_data)\n",
    "        #text1 = textract.process(\"temp.pdf\")\n",
    "        #text1 = text1.decode()\n",
    "        pdfFileObj = open('temp.pdf', 'rb')\n",
    "        pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "        n = len(pdfReader.pages)\n",
    "        text = ''\n",
    "        for i in range(n):\n",
    "            pageObj = pdfReader.pages[i]\n",
    "            text += pageObj.extract_text()\n",
    "        pdfFileObj.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b2fcbbc-e0e8-4686-84ba-33d61ec8678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mohnish.sonkusale\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\mohnish.sonkusale\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.2.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\mohnish.sonkusale\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mohnish.sonkusale\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mohnish.sonkusale\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mohnish.sonkusale\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca948672-4804-4071-a369-ea58428cac33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\mohnish.sonkusale\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4a5bc0d-3d8d-43e9-9a19-7dbbbecf2da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mohnish.sonkusale\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string # remove punctuation\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    " #spell correction\n",
    "# from textblob import TextBlob\n",
    "from nltk.corpus import wordnet #lemm\n",
    "def lemmatize(text):\n",
    "    words = text.split(' ')\n",
    "    lem = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in words:\n",
    "        tag = getPOS(nltk.pos_tag([i])[0][1][0].upper())\n",
    "        lem.append(lemmatizer.lemmatize(i, pos=tag))\n",
    "    text = words2text(lem)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab1c8e48-6292-4bf3-8e5e-e944654a671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPOS(tag):\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    if tag in tag_dict:\n",
    "        return tag_dict[tag]\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3da9700-1a73-4019-a71d-db35c62275cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2text(words):\n",
    "    text = ''\n",
    "    for i in words:\n",
    "        text += i + ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2c9d400-2916-470d-ba73-e93424e54518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mohamed HANNANI, Machine Learning Engineer\n",
      "Machine Learning Engineer with proven track record in develop and deploy high-performance ML models. Pro\u0000cient in\n",
      "Python, R, and PyTorch. Expert in data preprocessing, feature engineering, and model evaluation, developed predictive model with\n",
      "over 90% accuracy. Passionate about explore cutting-edge technique and leverage AI to solve complex problems. Seeking\n",
      "impactful opportunity to apply ML expertise and drive innovation in a dynamic environment.\n",
      "Sky Documents Anaysis\n",
      "Sky Bank Check\n",
      "Sky Signature\n",
      "Sky Face Analysis +212 6-46-746417  mohamed_hannani@yahoo.com  mhannani  in/mhannani  mhannani.me\n",
      "SUMMARY\n",
      "EXPERIENCE\n",
      "Data Engineer & Scientist Aug 2022 - July 2023, Casablanca, Morocco\n",
      "Indatacore\n",
      "Leader in digital industry base on arti\u0000cial intelligence and Deep Machine Learning technologies.\n",
      "●Led team to re\u0000ne data extraction from scan bills, cut processing time by 30% and boost system accuracy by 15%.\n",
      "●Collaborated with software engineer to deploy scalable machine learn model for SKyID use Docker and Kubernetes.\n",
      "●Implemented cutting-edge OCR solutions, achieve a 95% accuracy rate in verify bank check validity and eliminate manual\n",
      "veri\u0000cation needs.\n",
      "●Strategically design data cleaning and preprocessing pipeline for internal signature data, result in a remarkable 95%\n",
      "enhancement in data integrity and accuracy.\n",
      "●Applied algorithm for automatic extraction of vital information from bill documents, achieve an impressive 98% accuracy rate\n",
      "and reduce manual e\u0000ort while enhance data processing e\u0000ciency by 70%.\n",
      "Skills: Optimization AWS NLP MLOps PyTorch Transformers LLMs FastAPI Data Pipeline XML JSON\n",
      "Intern Data Scientist Mars 2022 - Aug 2022, Casablanca, Morocco\n",
      "Indatacore\n",
      "●Achieved a notable 97% accuracy in anti-spoo\u0000ng system, substantially mitigate the risk of unauthorized access to sensitive\n",
      "systems and result in a 50% decrease in security breach related to spoofed identities, reinforce comprehensive data protection.\n",
      "●Incorporated anti-spoo\u0000ng model into ReactJs app with TensorFlow.js, yield a 30% faster response time for liveness detection,\n",
      "enhancing user experience, and bolster defense against fraud attempts.\n",
      "Skills: Web Scraping Tensor\u0000ow Machine Learning PyTorch ETL Transformers GCP APIs React.js Apache Spark\n",
      "PROJECTS\n",
      "Sky Documents Analysis leverage deep machine learn technology to extract data from 156+ document types, revolutionizing\n",
      "information extraction.\n",
      "Skills: Optical Character Recognition (OCR) Image Processing Natural Language processing(NLP) AWS MLOps\n",
      "Sky Bank Check be a revolutionary bank check analysis and data extraction system. This intelligent system leveraged deep machine\n",
      "learning technology to analyze and extract data from more than 62 bank check types, revolutionize the banking industry.\n",
      "Skills: OCR Object Detection Transformers Image Processing Data Pipelines\n",
      "Sky Signature be a system that showcase the power of deep machine learn in signature analysis and pattern extraction from a\n",
      "diverse range of document type to intelligently detect and extract unique signature from document such a bank check and\n",
      "contracts.\n",
      "Skills: Machine Learning Business Analysis Recurrent Neural Networks Data Processing\n",
      "Sky Face Analysis leverage deep machine learn for face recognition, analysis, and liveness detection, o\u0000ering advanced identity\n",
      "veri\u0000cation and fraud detection capabilities.\n",
      "Skills: CNN Tenso\u0000ow.js React.js Web Development API Image ProcessingGenerative AI with Large Language Models\n",
      "Coursera • Aug 2023 - July 2023\n",
      "Natural Language Processing with Attention Models\n",
      "Coursera • June 2021 - Aug 2021\n",
      "Machine Learning\n",
      "Coursera • Apr 2021 - June 2021\n",
      "Apply Generative Adversarial Networks\n",
      "Coursera • May 2021 - July 2021\n",
      "Ph.D. Researcher\n",
      "National School of Electricity and Mechanics (ENSEM) • Casablanca, Morocco\n",
      "2023 - Ongoing\n",
      "Master of data science\n",
      "The University of Cadi Ayad • Marrakech, Morocco\n",
      "2020 – 2022\n",
      "Bachelor of Computer Science\n",
      "The University of Cadi Ayad • Marrakech, Morocco\n",
      "2017 – 2020\n",
      "Strong interpersonal and multilingual (English and French) communication abilities, adeptly collaborate with cross-functional\n",
      "teams to advance project objective and stimulate innovative solutions.\n",
      "Pro\u0000cient in Python, Scala, and R for data manipulation, analysis, and modeling.\n",
      "Pro\u0000cient in convert business objective and requirement into well-de\u0000ned technical architectures.\n",
      "Pro\u0000ciency in data engineering tool such a Ansible and Terraform, to automate infrastructure provisioning, con\u0000guration, and\n",
      "deployment processes.\n",
      "Maintains a curious and learning-oriented mindset to stay current with emerge technology and methodologies.\n",
      "Skilled at convey intricate analysis to non-technical audience use storytelling and data visualization.\n",
      "E\u0000ectively convey complex technical idea to diverse audiences.\n",
      "Pro\u0000cient in containerization with Docker and container orchestration with Kubernetes.\n",
      "Ability to articulate idea foster a cohesive and productive work environment.\n",
      "Pro\u0000cient in SQL and database management for data retrieval and manipulation.\n",
      "Experienced in conduct experiment and A/B testing.\n",
      "___\n",
      "Programming: Python R SQL Bash Javascript Java Go\n",
      "Deep Learning Frameworks: Keras Tensor\u0000ow PyTorch\n",
      "Frameworks: Django Flask Dash Plotly Shiny FastAPI Streamlit\n",
      "Libraries: Pandas Scikit-learn NumPy Matplotlib SciPy Seaborn\n",
      "Data Analytics Tools: Power BI Pentaho Talend IBM Cognos Analytics\n",
      "Developer Tools: Git Docker GitLab Jenkins GitHub\n",
      "Cloud: AWS GCP Azure\n",
      "Infrastructure Management: Terraform Ansible\n",
      "Data Integration: Informatica\n",
      "Cloud Data Warehousing: Snow\u0000ake\n",
      "Development Environment: Anaconda JupyterLab\n",
      "Big Data Technologies: Apache Spark Hadoop Apache Kafka  Apache Flink DataBricks\n",
      "Math: Statistics Probability Linear algebra.\n",
      "Misc: Data Mining Linux LaTeX Bash.\n",
      "Databases: PostgreSQL MongoDB MySQL\n",
      "Project Management Tools: JIRA.CERTIFICATES\n",
      "EDUCATION\n",
      "SKILLS \n"
     ]
    }
   ],
   "source": [
    "def text_preprocessing():\n",
    "    data = read_resume()\n",
    "    text = lemmatize(data)\n",
    "    return text\n",
    "text = text_preprocessing()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb6f02-c749-4403-98f7-5e84e814e832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016ab61-cb7a-4091-aa4a-819c4a59ce9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
